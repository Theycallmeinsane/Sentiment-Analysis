{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DP3-V6eWXqoV",
    "outputId": "95efed3b-d402-4b0b-b941-7535e313faee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "#mounting google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ADgiCgrXtLy",
    "outputId": "2114357a-5ce5-4185-8ec4-d81e00681982"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  review sentiment\n",
      "0      SAPS AT SEA <br /><br />Aspect ratio: 1.37:1<b...  negative\n",
      "1      If you want mindless action, hot chicks and a ...  positive\n",
      "2      \"The Woman in Black\" is easily one of the cree...  positive\n",
      "3      I can barely find the words to describe how mu...  negative\n",
      "4      What's in here ?! Let me tell you. It's the pr...  negative\n",
      "...                                                  ...       ...\n",
      "29995  I was really looking forward to this show give...  negative\n",
      "29996  I searched for this movie for years, apparentl...  positive\n",
      "29997  This is a story of the Winchester Rifle Model ...  positive\n",
      "29998  this film is in the MANDINGO & DRUM type<br />...  negative\n",
      "29999  Ha ha. - oh no - what to say about this film? ...  negative\n",
      "\n",
      "[30000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#opening the data file in read mode\n",
    "df = pd.read_csv('train.csv', sep=',')\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Ynk5CtWDbAfi"
   },
   "outputs": [],
   "source": [
    "reviews = df.iloc[:, 0].values  # Access first column (review)\n",
    "labels = df.iloc[:, 1].values   # Access second column (sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "19GKV9hsnGt2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mashh\\AppData\\Local\\Temp\\ipykernel_14300\\920268986.py:6: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html, 'html.parser')\n"
     ]
    }
   ],
   "source": [
    "#parsing html\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def parseHtml(html):\n",
    "  soup = BeautifulSoup(html, 'html.parser')\n",
    "  return soup.get_text()\n",
    "\n",
    "def removeDigits(string):\n",
    "  for i in range(10):\n",
    "    string=string.replace(str(i),' ')\n",
    "  return string\n",
    "\n",
    "#removing html\n",
    "reviews=list(map(parseHtml, reviews))\n",
    "\n",
    "#removing digits\n",
    "reviews=list(map(removeDigits, reviews))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TlJzPD7xROKl",
    "outputId": "f365341a-ed67-48e9-a0bc-763e3db34255"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mashh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#tokenizing\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "tokenizedText=[nltk.word_tokenize(item) for item in reviews]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "dyjJY4RMRJd1"
   },
   "outputs": [],
   "source": [
    "#removing punctuation\n",
    "punc = '''!()-[]{};:'\"\\, <>./?@#$%^&*_~'''\n",
    "tokenizedText= [[word for word in review if word not in punc] for review in tokenizedText]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mashh\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'SAPS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequence\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pad_sequences\n\u001b[0;32m      3\u001b[0m max_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m300\u001b[39m  \u001b[38;5;66;03m# Choose a maximum length that covers most of the sequences\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m padded_sequences \u001b[38;5;241m=\u001b[39m pad_sequences(tokenizedText, maxlen\u001b[38;5;241m=\u001b[39mmax_length, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(padded_sequences\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\data_utils.py:1132\u001b[0m, in \u001b[0;36mpad_sequences\u001b[1;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTruncating type \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtruncating\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m not understood\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# check `trunc` has expected shape\u001b[39;00m\n\u001b[1;32m-> 1132\u001b[0m trunc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(trunc, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trunc\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m!=\u001b[39m sample_shape:\n\u001b[0;32m   1134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of sample \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrunc\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m of sequence at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mposition \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is different from expected shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1137\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1138\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: 'SAPS'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8aCEDjcjMhmo",
    "outputId": "f8638505-93a0-44d9-b677-b384d3619017"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#splitting the Dataset into train and test set\n",
    "\n",
    "\n",
    "\n",
    "  # Convert to a NumPy array\n",
    " # Access the shape correctly\n",
    "totalRows = len(tokenizedText)\n",
    "splitRatio=0.75\n",
    "splitPoint=int(splitRatio*totalRows)\n",
    "\n",
    "trainReviews=tokenizedText[:splitPoint]\n",
    "trainLabels=labels[:splitPoint]\n",
    "testReviews=tokenizedText[splitPoint:]\n",
    "testLabels=labels[splitPoint:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "lejSbCrsBqXk"
   },
   "outputs": [],
   "source": [
    "#learning word embeddings on training data using Gensim library\n",
    "+\n",
    "++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "XakWbPClBg_z"
   },
   "outputs": [],
   "source": [
    "def getVectors(dataset):\n",
    "  singleDataItemEmbedding=np.zeros(embeddingsSize)\n",
    "  vectors=[]\n",
    "  for dataItem in dataset:\n",
    "    wordCount=0\n",
    "    for word in dataItem:\n",
    "      if word in model.wv.key_to_index:\n",
    "        singleDataItemEmbedding=singleDataItemEmbedding+model.wv[word]\n",
    "        wordCount=wordCount+1\n",
    "  \n",
    "    singleDataItemEmbedding=singleDataItemEmbedding/wordCount  \n",
    "    vectors.append(singleDataItemEmbedding)\n",
    "  return vectors\n",
    "\n",
    "trainReviewVectors=getVectors(trainReviews)\n",
    "testReviewVectors=getVectors(testReviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "WhobrCpvDrUc"
   },
   "outputs": [],
   "source": [
    "#Let's define a function that can display the accuracy, F1-score, label-wise precision, recall, etc. of each classifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "#add path of google drive to environment variable to load python files from google drive\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def printResults(y_true, y_predicted):\n",
    "  print(\"Accuracy= \", accuracy_score(y_true, y_predicted))\n",
    "\n",
    "  columns=['false', 'true']\n",
    "\n",
    "  precision, recall, fscore, support = score(y_true, y_predicted)\n",
    "\n",
    "  print('###########################################')\n",
    "  print('precision: {}'.format(precision))  \n",
    "  print('recall: {}'.format(recall))\n",
    "  print('fscore: {}'.format(fscore))\n",
    "  print('support: {}'.format(support))\n",
    "  print('###########################################3')\n",
    "\n",
    "  print('Macro F1 ',f1_score(y_true, y_predicted, average='macro'))\n",
    "\n",
    "  print('Micro F1 ', f1_score(y_true, y_predicted, average='micro'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "x_nAxHEZCEtz",
    "outputId": "bd3c382d-4a45-43c5-f2fa-cc6c6207e287"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################RESULTS OF NAIVE BAYES CLASSIFIER##################\n",
      "Accuracy=  0.6169333333333333\n",
      "###########################################\n",
      "precision: [0.51776246 0.71727468]\n",
      "recall: [0.64948454 0.59514801]\n",
      "fscore: [0.57619118 0.65052913]\n",
      "support: [3007 4493]\n",
      "###########################################3\n",
      "Macro F1  0.6133601556744168\n",
      "Micro F1  0.6169333333333333\n"
     ]
    }
   ],
   "source": [
    "#naive bayes\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clfNB = MultinomialNB()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaledTrainX= scaler.fit_transform(trainReviewVectors)\n",
    "scaledTestX = scaler.fit_transform(testReviewVectors)\n",
    "clfNB.fit(scaledTrainX, trainLabels)\n",
    "\n",
    "#test naive bayes accuracy\n",
    "testLabelsPredicted=list(clfNB.predict(scaledTestX))\n",
    "\n",
    "#print results\n",
    "print(\"####################RESULTS OF NAIVE BAYES CLASSIFIER##################\")\n",
    "printResults(testLabelsPredicted, testLabels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xW8P1L7eIKf3",
    "outputId": "4ca1a009-2547-4d1a-e5c3-11fe7ea52d9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################RESULTS OF NEURAL NETWORK CLASSIFIER##################\n",
      "Accuracy=  0.8254666666666667\n",
      "###########################################\n",
      "precision: [0.84544008 0.80525751]\n",
      "recall: [0.81455939 0.83737796]\n",
      "fscore: [0.8297125  0.82100369]\n",
      "support: [3915 3585]\n",
      "###########################################3\n",
      "Macro F1  0.825358096840683\n",
      "Micro F1  0.8254666666666667\n"
     ]
    }
   ],
   "source": [
    "#neural network\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clfMLP = MLPClassifier(hidden_layer_sizes=(10, 10, 10))\n",
    "clfMLP.fit(trainReviewVectors, trainLabels)\n",
    "  \n",
    "testLabelsPredicted=list(clfMLP.predict(testReviewVectors))\n",
    "\n",
    "#print results\n",
    "print(\"####################RESULTS OF NEURAL NETWORK CLASSIFIER##################\")\n",
    "printResults(testLabelsPredicted, testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uUJMx8OOZA66",
    "outputId": "0e16a5f7-a633-42cb-a617-7ded5ab5cd6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################RESULTS OF Random Forest CLASSIFIER##################\n",
      "Accuracy=  0.7854666666666666\n",
      "###########################################\n",
      "precision: [0.76723224 0.80391631]\n",
      "recall: [0.79834483 0.77341935]\n",
      "fscore: [0.78247938 0.78837301]\n",
      "support: [3625 3875]\n",
      "###########################################3\n",
      "Macro F1  0.7854261970937771\n",
      "Micro F1  0.7854666666666666\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clfRF = RandomForestClassifier(n_estimators = 1000)\n",
    "# Train the model on training data\n",
    "clfRF.fit(trainReviewVectors, trainLabels);\n",
    "\n",
    "testLabelsPredicted=list(clfRF.predict(testReviewVectors))\n",
    "\n",
    "#print results\n",
    "print(\"####################RESULTS OF Random Forest CLASSIFIER##################\")\n",
    "printResults(testLabelsPredicted, testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "W68M8x0v_lDM",
    "outputId": "7bc2cc27-ab9f-43a7-bfc9-d52b804f4268"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################RESULTS OF KNN Classifier##################\n",
      "Accuracy=  0.6964\n",
      "###########################################\n",
      "precision: [0.71818664 0.67435622]\n",
      "recall: [0.69054295 0.7028236 ]\n",
      "fscore: [0.70409357 0.68829569]\n",
      "support: [3923 3577]\n",
      "###########################################3\n",
      "Macro F1  0.6961946275682361\n",
      "Micro F1  0.6964\n"
     ]
    }
   ],
   "source": [
    "#KNN classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clfKNN = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Train the model on training data\n",
    "clfKNN.fit(trainReviewVectors, trainLabels);\n",
    "\n",
    "testLabelsPredicted=list(clfKNN.predict(testReviewVectors))\n",
    "\n",
    "#print results\n",
    "print(\"####################RESULTS OF KNN Classifier##################\")\n",
    "printResults(testLabelsPredicted, testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
