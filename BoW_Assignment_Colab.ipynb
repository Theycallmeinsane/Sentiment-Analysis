{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rr9ql4JXtkUn"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from transformers.generation import GenerationConfig\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import textwrap\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken accelerate transformers_stream_generator einops optimum  auto-gptq\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJ-TXrIytlwj",
        "outputId": "823be143-ac82-4415-9da6-92cb03f66c98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.27.2)\n",
            "Requirement already satisfied: transformers_stream_generator in /usr/local/lib/python3.10/dist-packages (0.0.4)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: optimum in /usr/local/lib/python3.10/dist-packages (1.16.2)\n",
            "Requirement already satisfied: auto-gptq in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: transformers>=4.26.1 in /usr/local/lib/python3.10/dist-packages (from transformers_stream_generator) (4.35.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from optimum) (15.0.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum) (1.12)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from optimum) (2.17.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.1.99)\n",
            "Requirement already satisfied: rouge in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (1.0.1)\n",
            "Requirement already satisfied: gekko in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (1.0.6)\n",
            "Requirement already satisfied: peft>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (0.8.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from auto-gptq) (4.66.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (0.15.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->transformers_stream_generator) (3.20.3)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->optimum) (10.0)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (15.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (3.9.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from rouge->auto-gptq) (1.16.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum) (1.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum) (2023.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIgQ89Y9tkUo",
        "outputId": "2d709870-853e-4fb6-e7b6-06eb241a25ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:transformers_modules.Qwen.Qwen-1_8B-Chat-Int4.62ee27f810e7f59905ee1dac4ccc86d593dd57f4.modeling_qwen:Try importing flash-attention for faster inference...\n",
            "WARNING:transformers_modules.Qwen.Qwen-1_8B-Chat-Int4.62ee27f810e7f59905ee1dac4ccc86d593dd57f4.modeling_qwen:Warning: import flash_attn rotary fail, please install FlashAttention rotary to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/rotary\n",
            "WARNING:transformers_modules.Qwen.Qwen-1_8B-Chat-Int4.62ee27f810e7f59905ee1dac4ccc86d593dd57f4.modeling_qwen:Warning: import flash_attn rms_norm fail, please install FlashAttention layer_norm to get higher efficiency https://github.com/Dao-AILab/flash-attention/tree/main/csrc/layer_norm\n",
            "WARNING:transformers_modules.Qwen.Qwen-1_8B-Chat-Int4.62ee27f810e7f59905ee1dac4ccc86d593dd57f4.modeling_qwen:Warning: import flash_attn fail, please install FlashAttention to get higher efficiency https://github.com/Dao-AILab/flash-attention\n"
          ]
        }
      ],
      "source": [
        "# Note: The default behavior now has injection attack prevention off.\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen-1_8B-Chat\", trust_remote_code=True)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"Qwen/Qwen-1_8B-Chat-Int4\", #\"Qwen/Qwen-7B-Chat-Int4\",\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ").eval()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IPXRqJK4tkUp"
      },
      "source": [
        "Solving class example using Qwen LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKxXqgmStkUr",
        "outputId": "69843fc2-852c-4ee1-ed4f-c508bb0b07c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The last sentence can be classified as having a sentiment of negative, but with\n",
            "some positivity in the description. It uses words like \"not nice\" and \"cold,\"\n",
            "which indicate that there are some negative aspects to the weather. However, the\n",
            "overall tone of the sentence is still negative due to the repeated use of the\n",
            "word \"not nice.\"\n"
          ]
        }
      ],
      "source": [
        "prompt = f\"\"\"\n",
        "Classify the last sentence using the following examples.\n",
        "\n",
        "<sentence>: it is nice weather\n",
        "<sentiment>: positive\n",
        "<sentence>: it is cold\n",
        "<sentiment>: negative\n",
        "<sentence>: it is not very cold\n",
        "<sentiment>: positive\n",
        "<sentence>: not nice\n",
        "<sentiment>: negative\n",
        "<sentence>: very cold\n",
        "<sentiment>: negative\n",
        "<sentence>: cold\n",
        "<sentiment>: negative\n",
        "<sentence>: very nice weather\n",
        "<sentiment>: positive\n",
        "<sentence>: it is not nice cold at all\n",
        "\n",
        "\"\"\"\n",
        "response, history = model.chat(tokenizer, prompt, history=None)\n",
        "print(textwrap.fill(response, width=80))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0oz4Ru_tkUs"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h50WiAMPtkUt"
      },
      "outputs": [],
      "source": [
        "sentences = [\"it is nice weather \", \"it is cold \", \"it is not very cold \", \"not nice \", \"very cold \", \"cold \", \"very nice weather \", \"it is not nice cold at all\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVFmEuHNtkUt"
      },
      "outputs": [],
      "source": [
        "text = \"it is not nice cold at all\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfRSPD9PtkUu"
      },
      "source": [
        "Using PLM (bert-finetune-sst2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6J8C77LtkUu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "outputId": "927b097b-efdd-4def-918e-10fa4a0ee52e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      label     score\n",
              "0  NEGATIVE  0.999766"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-60a0b46d-8f02-4498-bc0e-b8ef57b7ae3c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>0.999766</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60a0b46d-8f02-4498-bc0e-b8ef57b7ae3c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-60a0b46d-8f02-4498-bc0e-b8ef57b7ae3c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-60a0b46d-8f02-4498-bc0e-b8ef57b7ae3c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"pd\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"NEGATIVE\"\n        ],\n        \"num_unique_values\": 1,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": NaN,\n        \"min\": 0.9997656941413879,\n        \"max\": 0.9997656941413879,\n        \"samples\": [\n          0.9997656941413879\n        ],\n        \"num_unique_values\": 1,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "classifier = pipeline(\"text-classification\")\n",
        "outputs = classifier(text)\n",
        "pd.DataFrame(outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yxImh-_tkUu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc2a27ef-daab-4aaa-8af0-efa2ee1fa254"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "it is nice weather  POSITIVE 0.9998561143875122\n",
            "it is cold  NEGATIVE 0.9996206760406494\n",
            "it is not very cold  POSITIVE 0.9659685492515564\n",
            "not nice  NEGATIVE 0.9997665286064148\n",
            "very cold  NEGATIVE 0.999714195728302\n",
            "cold  NEGATIVE 0.9997304081916809\n",
            "very nice weather  POSITIVE 0.9998589754104614\n",
            "it is not nice cold at all NEGATIVE 0.9997656941413879\n"
          ]
        }
      ],
      "source": [
        "for s in sentences:\n",
        "    outputs = classifier(s)\n",
        "    print(s, outputs[0]['label'], outputs[0]['score'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbUw6ReftkUv"
      },
      "source": [
        "Using Qwen to evaluate all the 8 comments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nuvoE49CtkUv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c89b606a-0101-4fb9-e674-c991048a791a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 : it is nice weather \n",
            "The sentiment of the text \"it is nice weather\" can be considered positive\n",
            "because the use of words such as \"nice\" indicates a favorable opinion of the\n",
            "weather conditions.  Probability: It's difficult to provide an exact probability\n",
            "without additional context and information about the reader's beliefs and\n",
            "opinions on weather. However, based on common sentiment analysis techniques, a\n",
            "positive sentiment score for this text would likely be around 0.75-0.85. This\n",
            "suggests that a majority of people would consider the weather to be pleasant.\n",
            "----------------------------------\n",
            "1 : it is cold \n",
            "The sentiment of the text \"it is cold\" can be interpreted as negative because it\n",
            "suggests that the weather is unpleasant and uncomfortable. The probability of\n",
            "this sentiment being positive would be low due to the use of negative words such\n",
            "as \"cold\" and \"unpleasant.\"\n",
            "----------------------------------\n",
            "2 : it is not very cold \n",
            "The sentiment of the text can be determined by analyzing the words and phrases\n",
            "used in it. In this case, there are no positive or negative words that indicate\n",
            "a strong emotional response to the weather.  Therefore, my answer is \"neutral.\"\n",
            "The probability of a positive or negative sentiment for this text cannot be\n",
            "determined based on the given information.\n",
            "----------------------------------\n",
            "3 : not nice \n",
            "Based on the given text, it appears to be a negative sentiment as it contains\n",
            "words like \"not nice.\" The sentiment score for this text would likely fall\n",
            "within the range of -1 to 1, where -1 indicates a strongly negative sentiment\n",
            "and 1 indicates a strongly positive sentiment. In this case, I would recommend\n",
            "selecting the option \"negative\" with a probability close to 100%.\n",
            "----------------------------------\n",
            "4 : very cold \n",
            "The sentiment of the given text is negative, as it describes a very cold\n",
            "environment. The word \"cold\" itself has a negative connotation, and the triple\n",
            "backticks indicate that the sentiment is subjective and individual. Therefore,\n",
            "the probability of the answer being positive would be low.\n",
            "----------------------------------\n",
            "5 : cold \n",
            "Based on the given text, it appears to be written in a negative sentiment, as\n",
            "there is no positive or neutral connotation expressed. Therefore, the sentiment\n",
            "of this text is \"negative\". The probability of an answer in this case would\n",
            "depend on various factors such as the context and the specific guidelines\n",
            "provided for answering questions related to language analysis. However, based\n",
            "solely on the given text alone, it can be concluded that the sentiment is\n",
            "negative.\n",
            "----------------------------------\n",
            "6 : very nice weather \n",
            "The sentiment of the given text is positive. The word \"nice\" indicates a\n",
            "favorable opinion, and the triple backticks around it suggest that the author is\n",
            "expressing strong approval. Therefore, my response is \"positive\". The\n",
            "probability of this answer being correct can vary depending on the context and\n",
            "interpretation of the double backticks, but based on their usage alone, it seems\n",
            "likely to be a positive sentiment.\n",
            "----------------------------------\n",
            "7 : it is not nice cold at all\n",
            "The sentiment of the given text can be interpreted as negative, as it contains\n",
            "words such as \"not nice\" and \"cold\", which convey a sense of dissatisfaction or\n",
            "discomfort. The probability of this sentiment being positive would depend on\n",
            "other factors, such as the context in which the text is being used and the\n",
            "reader's emotional response to the language used. However, based solely on the\n",
            "text provided, I would conclude that the sentiment is negative.\n",
            "----------------------------------\n"
          ]
        }
      ],
      "source": [
        "for i, s in enumerate(sentences):\n",
        "    text = s\n",
        "    print(i, \":\", text)\n",
        "    prompt = f\"\"\"\n",
        "    What is the sentiment of the following text, which is delimited with triple backticks?\n",
        "\n",
        "    Give your answer as either \"positive\" or \"negative\". If possible, also share the probability of your answer.\n",
        "    Review text: '''{text}'''\n",
        "    \"\"\"\n",
        "    response, history = model.chat(tokenizer, prompt, history=None)\n",
        "    print(textwrap.fill(response, width=80))\n",
        "    print(\"----------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXmWzf6qtkUv"
      },
      "source": [
        "Loading IMDB dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QAltxPFqtkUw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41ce430f-b56d-492d-8aa3-83850dab4e19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                  review sentiment\n",
            "0      SAPS AT SEA <br /><br />Aspect ratio: 1.37:1<b...  negative\n",
            "1      If you want mindless action, hot chicks and a ...  positive\n",
            "2      \"The Woman in Black\" is easily one of the cree...  positive\n",
            "3      I can barely find the words to describe how mu...  negative\n",
            "4      What's in here ?! Let me tell you. It's the pr...  negative\n",
            "...                                                  ...       ...\n",
            "29995  I was really looking forward to this show give...  negative\n",
            "29996  I searched for this movie for years, apparentl...  positive\n",
            "29997  This is a story of the Winchester Rifle Model ...  positive\n",
            "29998  this film is in the MANDINGO & DRUM type<br />...  negative\n",
            "29999  Ha ha. - oh no - what to say about this film? ...  negative\n",
            "\n",
            "[30000 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# load the dataset\n",
        "'''with open('train.csv','r',encoding=\"utf8\") as f:\n",
        "    document = f.readlines()\n",
        "f.close()\n",
        "\n",
        "labels, texts = [], []\n",
        "for line in document:\n",
        "    content = line.split()\n",
        "    label = content[0]\n",
        "    labels.append(label[-1])\n",
        "    texts.append(\" \".join(content[1:]))\n",
        "    print(len(labels), len(texts))\n",
        "'''\n",
        "df=pd.read_csv(\"train.csv\")\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-WbzNcn-tkUw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4a8c8e9-b28f-43b8-dd9a-d8bc738e656c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAPS AT SEA <br /><br />Aspect ratio: 1.37:1<br /><br />Sound format: Mono<br /><br />(Black and white)<br /><br />Suffering from 'hornophobia', Ollie embarks on a 'restful' boat trip, but he and Stan get mixed up with an escaped convict (Rychard Cramer). Chaos ensues.<br /><br />This feature length comedy - an OK entry which nonetheless unspools like a mere imitation of Laurel and Hardy's best work - marked the final collaboration between L&H and producer Hal Roach. Episodic in structure, the movie culminates in a memorable ocean voyage after The Boys are taken hostage by villainous Cramer (who shoots a seagull to prove how tough he is!). The gags are OK, but inspiration is lacking, perhaps due to the recruitment of actor-turned-director Gordon Douglas, previously responsible for Ollie's first solo effort in the sound era (ZENOBIA, produced in 1939), but whose work here lacks a measure of pzazz. Fair, but nothing special. L&H regulars Charlie Hall and James Finlayson make guest appearances. \n",
            "\n",
            "If you want mindless action, hot chicks and a post-apocalyptic view of Seattle, then this is the show for you!<br /><br />The concept of Dark Angel isn't anything new (in fact, there's controversy over whether James Cameron stole the idea from a book), but I spend the entire hour watching it every Tuesday from start to finish.<br /><br />Jessica Alba is smoking and Max' friends (original Cindy, Kendra) are just as hot. <br /><br />The fight scenes are getting better, but the dialogues between Original Cindy and Max need to be a little bit better (the slang sounds forced and it sounds like someone living in the suburbs wrote it).<br /><br />In my opinion, Dark Angel is a great guilty pleasure filled with everything an action fan could ask for, but if you're looking for hard hitting, award-winning drama, go watch \"The West Wing\" or something. \n",
            "\n",
            "\"The Woman in Black\" is easily one of the creepiest British ghost stories ever made.A young solicitor,after arriving in a small town to handle a dead client's estate,is haunted by a mysterious woman dressed all in black.The film is loaded with extremely eerie atmosphere and the frights are calculated for and deliver the maximum effect possible.The action keeps the viewer deeply involved and the finale is quite disturbing.The acting is excellent and the tension is almost unbearable at times.So if you want to see a truly creepy horror film give this one a look.I dare anyone to watch \"The Woman in Black\" alone at night with the lights off.Highly recommended.10 out of 10. \n",
            "\n",
            "I can barely find the words to describe how much this piece of trash offended me. Why is it that American filmmakers always go out of there way to portray Jamaicans as a bunch of backwards ass bush babies and worse yet, cast people to play Jamaicans who sound utterly ridiculous when they try to imitate the accent? We are not all extremely dark, we do not all walk around carrying machetes whether for work OR PROTECTION, we do not walk around naked in our homes and we do not practice VOODOO!! We are doctors, lawyers, architects, Businessmen and women, musicians, actors AND FILMMAKERS. I am sick and tired of watching all of these portrayals of Jamaicans as a bunch of dreadlock wearing Rastafarians who do nothing but sit around all day smoking weed on a beach or shooting guns in the air (When we're not living in our tree houses). YES, we wear clothes. YES, we have electricity. No, weed is not legal on the island AND CHANCES ARE WE SPEAK BETTER English THAN YOU! The worst part is, this isn't just me being angry and bitter, these are actual answers to questions that most Jamaicans who have traveled overseas have been asked at some point. Read a book before you assume what's it's like in another country and worse yet, decide to make a movie about it.<br /><br />WELCOME TO JAMAICA! The land where all we do is murder white people and beat our bongos drums...Tales from the Crypt has officially sickened me, along with the entire crew of people who worked on this garbage, especially the writer. \n",
            "\n",
            "What's in here ?! Let me tell you. It's the presence of (Alec Baldwin). He's not a great actor but maybe a nice star with some good movies which this is not one of them. He did nothing here more than anything he did before or after. So not to mention (literally !) the matter of (Steve McQueen) being at the same role in the original because I don't want to make that comparison in the first place. I'm not a big fan or even a fan of (Kim Basinger), she got a lot of bad movies on her and even at her best she looks average ! And it gets on my nerve indeed whenever they talk about her seductive rare beauty !!?? Well, if being a blond would make anyone captivating then I'll dye my hair in yellow as soon as possible ! And what is it with all the craziness over miss Basinger's Legs ??!! It's surely insanity or bad tasting ? As I don't see them both as not sexy only, but UGLY too ! And if you hate that so shoot me down but you know what ?! I've just watched this movie so I'm dead already !. Yet, what would make you really suffer in unbearable way is that nothing of the credits goes to the one she deserves the mostAnd of course I mean (Jennifer Tilly)..Now we're talking about a true genuine seductive chick with such unforgettable body and one unique sense of allurement like a nasty brunette (Marilyn Monroe) however much more healthier !! (I can't help it, she was the only new and watchable thing in here !). (Michael Madsen) as the bad guy was much appealing as well as effective more than the good guys, (James Woods) is here to summarize the early events beside the pool (so the trailer would be by his voice later !) and he knew before all that this is a whole Hollywood's stuff so \"Do your thing, take your cash, and good luck as an actor in other movies !\", the editing gave the movie a serious personality along with violent atmosphere done by suitable shining cinematography, so the main goods of it (The action, The thrill, ..) are here and fairly well-made, though any echo for deep meanings about (the kinds of betrayal) as the main dramatic motif of the whole thing is not that strong so don't wait for it. OK, it's all in all another remake without anything special (Except Jennifer Tilly's spicy moments !) so I think I tried to be objective as much as I could therefore I shouldn't end my review saying that (Basinger) or anyone here did better than this movie.. It would be an insult because frankly.. Anything is better than this movie! \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range (0,5):\n",
        "  print(df.iloc[i]['review'],'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sz2Ht9BItkUx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f7daa4c-d099-448f-dba8-55785d5e9dc1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    negative\n",
              "1    positive\n",
              "2    positive\n",
              "3    negative\n",
              "4    negative\n",
              "5    negative\n",
              "6    positive\n",
              "7    negative\n",
              "8    negative\n",
              "9    negative\n",
              "Name: sentiment, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df.iloc[0:10]['sentiment']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLSP6o-0tkUx"
      },
      "source": [
        "Preparing BoW using CountVectorizer and TfidfVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aetiaBl5tkUx"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLSkKVtLtkUx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aafc7bd-aad4-4609-9759-c3839168da75"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30000, 82737)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "cnt_vectorizer = CountVectorizer()\n",
        "features = cnt_vectorizer.fit_transform(df['review'])\n",
        "features_nd = features.toarray()\n",
        "features_nd.shape\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(features_nd)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaVNPg5Xn9DY",
        "outputId": "819fd088-a47a-42d6-854a-50c80af21799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNFt7GKHtkUy"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVxi0_4GtkUy"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test  = train_test_split(features_nd, df['sentiment'], train_size=0.75,random_state=1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvk1gd2ItkUy"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfcXEhg3tkUy"
      },
      "outputs": [],
      "source": [
        "clf1 = MultinomialNB()\n",
        "clf1.fit(X_train, y_train)\n",
        "y_pred = clf1.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30uL-88-tkUy"
      },
      "outputs": [],
      "source": [
        "cnt_vectorizer = CountVectorizer(ngram_range=(1, 2),max_features=100)\n",
        "features = cnt_vectorizer.fit_transform(texts)\n",
        "features_nd = features.toarray()\n",
        "print(features_nd.shape)\n",
        "X_train, X_test, y_train, y_test  = train_test_split(features_nd, labels, train_size=0.75,random_state=1234)\n",
        "clf1 = MultinomialNB()\n",
        "clf1.fit(X_train, y_train)\n",
        "y_pred = clf1.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68FSykFQtkUy"
      },
      "outputs": [],
      "source": [
        "cnt_vectorizer = CountVectorizer(ngram_range=(1, 2),max_features=200)\n",
        "features = cnt_vectorizer.fit_transform(texts)\n",
        "features_nd = features.toarray()\n",
        "print(features_nd.shape)\n",
        "X_train, X_test, y_train, y_test  = train_test_split(features_nd, labels, train_size=0.75,random_state=1234)\n",
        "clf1 = MultinomialNB()\n",
        "clf1.fit(X_train, y_train)\n",
        "y_pred = clf1.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28uU4vhOtkUz"
      },
      "outputs": [],
      "source": [
        "cnt_vectorizer = CountVectorizer(ngram_range=(1, 2),max_features=500)\n",
        "features = cnt_vectorizer.fit_transform(texts)\n",
        "features_nd = features.toarray()\n",
        "print(features_nd.shape)\n",
        "X_train, X_test, y_train, y_test  = train_test_split(features_nd, labels, train_size=0.75,random_state=1234)\n",
        "clf1 = MultinomialNB()\n",
        "clf1.fit(X_train, y_train)\n",
        "y_pred = clf1.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6ThxWU3tkUz"
      },
      "outputs": [],
      "source": [
        "cnt_vectorizer = CountVectorizer(ngram_range=(1, 2),max_features=2000)\n",
        "features = cnt_vectorizer.fit_transform(texts)\n",
        "features_nd = features.toarray()\n",
        "print(features_nd.shape)\n",
        "X_train, X_test, y_train, y_test  = train_test_split(features_nd, labels, train_size=0.75,random_state=1234)\n",
        "clf1 = MultinomialNB()\n",
        "clf1.fit(X_train, y_train)\n",
        "y_pred = clf1.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Pu6a9NwtkUz"
      },
      "outputs": [],
      "source": [
        "cnt_vectorizer = CountVectorizer(ngram_range=(1, 5),max_features=2000)\n",
        "features = cnt_vectorizer.fit_transform(texts)\n",
        "features_nd = features.toarray()\n",
        "print(features_nd.shape)\n",
        "X_train, X_test, y_train, y_test  = train_test_split(features_nd, labels, train_size=0.75,random_state=1234)\n",
        "clf1 = MultinomialNB()\n",
        "clf1.fit(X_train, y_train)\n",
        "y_pred = clf1.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VlQ0eG_ptkUz"
      },
      "outputs": [],
      "source": [
        "cnt_vectorizer = CountVectorizer(ngram_range=(1, 3),max_features=5000)\n",
        "features = cnt_vectorizer.fit_transform(texts)\n",
        "features_nd = features.toarray()\n",
        "print(features_nd.shape)\n",
        "X_train, X_test, y_train, y_test  = train_test_split(features_nd, labels, train_size=0.75,random_state=1234)\n",
        "clf1 = MultinomialNB()\n",
        "clf1.fit(X_train, y_train)\n",
        "y_pred = clf1.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYPvMNA6tkU0"
      },
      "outputs": [],
      "source": [
        "tfidf_vectorizer = TfidfVectorizer()#(ngram_range=(1, 3),max_features=5000)\n",
        "features = tfidf_vectorizer.fit_transform(texts)\n",
        "features_nd = features.toarray()\n",
        "print(features_nd.shape)\n",
        "X_train, X_test, y_train, y_test  = train_test_split(features_nd, labels, train_size=0.75,random_state=1234)\n",
        "clf1 = MultinomialNB()\n",
        "clf1.fit(X_train, y_train)\n",
        "y_pred = clf1.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lY9ZRoAptkU0"
      },
      "outputs": [],
      "source": [
        "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 3),max_features=5000)\n",
        "features = tfidf_vectorizer.fit_transform(texts)\n",
        "features_nd = features.toarray()\n",
        "print(features_nd.shape)\n",
        "X_train, X_test, y_train, y_test  = train_test_split(features_nd, labels, train_size=0.75,random_state=1234)\n",
        "clf1 = MultinomialNB()\n",
        "clf1.fit(X_train, y_train)\n",
        "y_pred = clf1.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v_ZBHxfutkU0"
      },
      "outputs": [],
      "source": [
        "clf1 = RandomForestClassifier()\n",
        "clf1.fit(X_train, y_train)\n",
        "y_pred = clf1.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgru2VQ5tkU0"
      },
      "outputs": [],
      "source": [
        "clf1 = KNeighborsClassifier()\n",
        "clf1.fit(X_train, y_train)\n",
        "y_pred = clf1.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y42A13h0tkU1"
      },
      "outputs": [],
      "source": [
        "X_train2, X_test2, y_train, y_test  = train_test_split(texts, labels, train_size=0.75,random_state=1234)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DaRHT2RtkU1"
      },
      "source": [
        "Evaluating all 2500 test records using PLM (bert-finetuned-sst)\n",
        "\n",
        "This may take upto 2-3 minutes on your local machine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JES6gbOtkU1"
      },
      "outputs": [],
      "source": [
        "bert_pred = []\n",
        "for s in X_test2:\n",
        "    outputs = classifier(s)\n",
        "    bert_pred.append(outputs[0]['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhP7o2YttkU1"
      },
      "outputs": [],
      "source": [
        "#map 'Positive' to 2 and 'Negative' to 1 in bert_pred list\n",
        "bert_pred2 = []\n",
        "for s in bert_pred:\n",
        "    if s == 'POSITIVE':\n",
        "        bert_pred2.append('2')\n",
        "    else:\n",
        "        bert_pred2.append('1')\n",
        "accuracy_score(y_test, bert_pred2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TuUXXwSLtkU2"
      },
      "outputs": [],
      "source": [
        "# take top 100 records from X_test2\n",
        "X_test2a = X_test[0:100]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Vf8ckt7-CMlX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "df.head(10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "GlEm0q5lEiJW",
        "outputId": "a2b3d728-53b3-4fd8-f8e0-86449eb3ed09"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  SAPS AT SEA <br /><br />Aspect ratio: 1.37:1<b...  negative\n",
              "1  If you want mindless action, hot chicks and a ...  positive\n",
              "2  \"The Woman in Black\" is easily one of the cree...  positive\n",
              "3  I can barely find the words to describe how mu...  negative\n",
              "4  What's in here ?! Let me tell you. It's the pr...  negative\n",
              "5  This is the story of a maniac cop who, for som...  negative\n",
              "6  Before I continue forth with the new millenniu...  positive\n",
              "7  When Rodney Dangerfield is on a roll, he's hil...  negative\n",
              "8  Prom Night is shot with the artistic eye someo...  negative\n",
              "9  \"Destroy All Planets\" winds up settling for 'd...  negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ee0d0ebf-03a5-48bb-86e4-c4c20a50d685\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SAPS AT SEA &lt;br /&gt;&lt;br /&gt;Aspect ratio: 1.37:1&lt;b...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>If you want mindless action, hot chicks and a ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"The Woman in Black\" is easily one of the cree...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I can barely find the words to describe how mu...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What's in here ?! Let me tell you. It's the pr...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>This is the story of a maniac cop who, for som...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Before I continue forth with the new millenniu...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>When Rodney Dangerfield is on a roll, he's hil...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Prom Night is shot with the artistic eye someo...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>\"Destroy All Planets\" winds up settling for 'd...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee0d0ebf-03a5-48bb-86e4-c4c20a50d685')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ee0d0ebf-03a5-48bb-86e4-c4c20a50d685 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ee0d0ebf-03a5-48bb-86e4-c4c20a50d685');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-31934281-4002-4ccc-b95c-cbfab97b81e2\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-31934281-4002-4ccc-b95c-cbfab97b81e2')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-31934281-4002-4ccc-b95c-cbfab97b81e2 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 30000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"Occasionally I accidentally leave the television on after \\\"South Park\\\" and I end up catching some of the train wreck of middle school humor that is \\\"Mind of Mencia\\\". It's the only time I wish my room was cleaner because I'd be able to find the remote that much faster. The truth is Comedy Central was in need of a replacement \\\"Chappelle's Show\\\", and what they got was a show that appeals to idiots that either miss Dave so much they'll cling to any minority variety show, or are satisfied with the plain \\\"Mexicans love tacos\\\" jokes that Carlos Mencia shovels in every week. I am to understand, though, that there are some people out there that actually find Mencia *shudder* funny. I firmly stand by my words when I say I believe these people to exist only in myth. However, if you are indeed out there, I ask only that you never enter into my housing district, and read these major differences between Carlos and \\\"Chappelle's Show\\\": <br /><br />1) Dave was funny. You may want to highlight this one. <br /><br />2) \\\"Chappelle's Show\\\" was FIVE TIMES as edgy as Mencia could ever hope to be. Yet every time a promo for his little show airs, it's all about him, tooting his own horn about how he's nothing we've ever seen before. You've got that right, Carlos. And not in a good way. Chappelle didn't need to tell people he was edgy and funny. We all just kind of stuck around to watch the show to find out for ourselves.<br /><br />3) Chappelle actually had race jokes that dove into some depth of the different cultures- things that some people didn't know about. Like his \\\"I know black people\\\" game segment. The grand prize was some hair cream that black people use. That's deeper than Mencia would ever dare to dive. So how dare he call himself edgy? If Mencia were writing that sketch the grand prize would have been fried chicken and kool-aid. And my accusations have some merit. I saw a promo for his show (which I have affectionately come to call 'My T.V. Monitor Taking A S--t For Thirty Minutes') a few days ago and it was some stereotype olympics sketch, which i admitted to myself was a pretty funny concept. Then I saw that the Mexican that won received a green card as a grand prize. That's it?! That's as close to the fire as you wanna get? Who COULDN'T think of that- back in 7th grade? For you fans of the show, if you're ever watching and you miss one of his punchlines- perhaps because you and your friends were discussing how \\\"Duh-De-Durr\\\" never gets old and is in no way the part of the joke where someone funny would have something clever to say- just remember that there are only five possible choices for punchlines anyway: green card, tacos, border jumpers, lawn mowers, and of course, duh-de-dur. Just remember-whichever it was, it was screamed. Enjoy!<br /><br />4) Kind of relating to number two. Every time he says something that gets a laugh, he'll pause to tell people (while laughing at his own joke) that he thinks he \\\"went too far with that last one\\\". Then don't say it for God's sake. Or let the people decide by themselves. He and Comedy Central keep shoving this tripe down my throat that he's this tell-it-like-it-is show that is more controversial than \\\"The Da Vinci Code\\\". You're not. You never will be. <br /><br />I've never been offended by the show's content. I would never give it that much credit. I'm offended that Carlos Mencia is given thirty minutes to scream unnecessarily. Yeah... I'm literally offended by that fact.\",\n          \"I never thought I would absolutly hate an Arnold Schwartzeneggar film, BUT this is is dreadful from the get go. there isnt one redeemable scene in the entire 123 long minutes. an absolute waste of time<br /><br /> thank yu<br /><br /> Jay harris\",\n          \"A beautiful movie, especially if you like horses,WWII films and the austere Hungarian Plateau.A story of courage, compassion and loyalty that transcends generations. The horsemanship is spectacular as well as the main characters' horse in his own training.<br /><br />I will buy this movie and watch it again. This is a family film and I recommend it highly.A good ''Family Nite'' movie. Although there are some violent scenes, it was the Nazi occupation of Hungary.The native people were very interesting in the way they stood their ground even in the face of certain death from a Nazi officer who had his own personal reasons for hunting down Brady.A hauntingly beautiful film.\"\n        ],\n        \"num_unique_values\": 29853,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"samples\": [\n          \"positive\",\n          \"negative\"\n        ],\n        \"num_unique_values\": 2,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range (0,5):\n",
        "  print({i},df.iloc[i]['review'],'\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyQj8VC9EwAE",
        "outputId": "5c2e70f7-2980-41af-f907-1fcdee2b0097"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0} SAPS AT SEA <br /><br />Aspect ratio: 1.37:1<br /><br />Sound format: Mono<br /><br />(Black and white)<br /><br />Suffering from 'hornophobia', Ollie embarks on a 'restful' boat trip, but he and Stan get mixed up with an escaped convict (Rychard Cramer). Chaos ensues.<br /><br />This feature length comedy - an OK entry which nonetheless unspools like a mere imitation of Laurel and Hardy's best work - marked the final collaboration between L&H and producer Hal Roach. Episodic in structure, the movie culminates in a memorable ocean voyage after The Boys are taken hostage by villainous Cramer (who shoots a seagull to prove how tough he is!). The gags are OK, but inspiration is lacking, perhaps due to the recruitment of actor-turned-director Gordon Douglas, previously responsible for Ollie's first solo effort in the sound era (ZENOBIA, produced in 1939), but whose work here lacks a measure of pzazz. Fair, but nothing special. L&H regulars Charlie Hall and James Finlayson make guest appearances. \n",
            "\n",
            "{1} If you want mindless action, hot chicks and a post-apocalyptic view of Seattle, then this is the show for you!<br /><br />The concept of Dark Angel isn't anything new (in fact, there's controversy over whether James Cameron stole the idea from a book), but I spend the entire hour watching it every Tuesday from start to finish.<br /><br />Jessica Alba is smoking and Max' friends (original Cindy, Kendra) are just as hot. <br /><br />The fight scenes are getting better, but the dialogues between Original Cindy and Max need to be a little bit better (the slang sounds forced and it sounds like someone living in the suburbs wrote it).<br /><br />In my opinion, Dark Angel is a great guilty pleasure filled with everything an action fan could ask for, but if you're looking for hard hitting, award-winning drama, go watch \"The West Wing\" or something. \n",
            "\n",
            "{2} \"The Woman in Black\" is easily one of the creepiest British ghost stories ever made.A young solicitor,after arriving in a small town to handle a dead client's estate,is haunted by a mysterious woman dressed all in black.The film is loaded with extremely eerie atmosphere and the frights are calculated for and deliver the maximum effect possible.The action keeps the viewer deeply involved and the finale is quite disturbing.The acting is excellent and the tension is almost unbearable at times.So if you want to see a truly creepy horror film give this one a look.I dare anyone to watch \"The Woman in Black\" alone at night with the lights off.Highly recommended.10 out of 10. \n",
            "\n",
            "{3} I can barely find the words to describe how much this piece of trash offended me. Why is it that American filmmakers always go out of there way to portray Jamaicans as a bunch of backwards ass bush babies and worse yet, cast people to play Jamaicans who sound utterly ridiculous when they try to imitate the accent? We are not all extremely dark, we do not all walk around carrying machetes whether for work OR PROTECTION, we do not walk around naked in our homes and we do not practice VOODOO!! We are doctors, lawyers, architects, Businessmen and women, musicians, actors AND FILMMAKERS. I am sick and tired of watching all of these portrayals of Jamaicans as a bunch of dreadlock wearing Rastafarians who do nothing but sit around all day smoking weed on a beach or shooting guns in the air (When we're not living in our tree houses). YES, we wear clothes. YES, we have electricity. No, weed is not legal on the island AND CHANCES ARE WE SPEAK BETTER English THAN YOU! The worst part is, this isn't just me being angry and bitter, these are actual answers to questions that most Jamaicans who have traveled overseas have been asked at some point. Read a book before you assume what's it's like in another country and worse yet, decide to make a movie about it.<br /><br />WELCOME TO JAMAICA! The land where all we do is murder white people and beat our bongos drums...Tales from the Crypt has officially sickened me, along with the entire crew of people who worked on this garbage, especially the writer. \n",
            "\n",
            "{4} What's in here ?! Let me tell you. It's the presence of (Alec Baldwin). He's not a great actor but maybe a nice star with some good movies which this is not one of them. He did nothing here more than anything he did before or after. So not to mention (literally !) the matter of (Steve McQueen) being at the same role in the original because I don't want to make that comparison in the first place. I'm not a big fan or even a fan of (Kim Basinger), she got a lot of bad movies on her and even at her best she looks average ! And it gets on my nerve indeed whenever they talk about her seductive rare beauty !!?? Well, if being a blond would make anyone captivating then I'll dye my hair in yellow as soon as possible ! And what is it with all the craziness over miss Basinger's Legs ??!! It's surely insanity or bad tasting ? As I don't see them both as not sexy only, but UGLY too ! And if you hate that so shoot me down but you know what ?! I've just watched this movie so I'm dead already !. Yet, what would make you really suffer in unbearable way is that nothing of the credits goes to the one she deserves the mostAnd of course I mean (Jennifer Tilly)..Now we're talking about a true genuine seductive chick with such unforgettable body and one unique sense of allurement like a nasty brunette (Marilyn Monroe) however much more healthier !! (I can't help it, she was the only new and watchable thing in here !). (Michael Madsen) as the bad guy was much appealing as well as effective more than the good guys, (James Woods) is here to summarize the early events beside the pool (so the trailer would be by his voice later !) and he knew before all that this is a whole Hollywood's stuff so \"Do your thing, take your cash, and good luck as an actor in other movies !\", the editing gave the movie a serious personality along with violent atmosphere done by suitable shining cinematography, so the main goods of it (The action, The thrill, ..) are here and fairly well-made, though any echo for deep meanings about (the kinds of betrayal) as the main dramatic motif of the whole thing is not that strong so don't wait for it. OK, it's all in all another remake without anything special (Except Jennifer Tilly's spicy moments !) so I think I tried to be objective as much as I could therefore I shouldn't end my review saying that (Basinger) or anyone here did better than this movie.. It would be an insult because frankly.. Anything is better than this movie! \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[0:10]['sentiment']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qCjR8X9ExS8",
        "outputId": "ad24fb93-19a9-49ba-f7f9-9819e529825f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    negative\n",
              "1    positive\n",
              "2    positive\n",
              "3    negative\n",
              "4    negative\n",
              "5    negative\n",
              "6    positive\n",
              "7    negative\n",
              "8    negative\n",
              "9    negative\n",
              "Name: sentiment, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import tree\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "JaFNM4bfCJNa"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, param_grid, vectorizer, ngram_range, max_features):\n",
        "    cnt_vectorizer = vectorizer(ngram_range=ngram_range, max_features=max_features)\n",
        "    features = cnt_vectorizer.fit_transform(df['review'])\n",
        "    features_nd = features.toarray()\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features_nd, df['sentiment'], train_size=0.75, random_state=1234)\n",
        "\n",
        "    grid_search = GridSearchCV(model, param_grid, cv=3)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = grid_search.predict(X_test)\n",
        "    print(\"Model Name:\", model.__class__.__name__, \"\\n\", \"Ngram Range:\", ngram_range, \"\\n\", \"Max Features:\", max_features, \"\\n\", \"Vectorizer:\", vectorizer.__name__, \"\\n\", \"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Best parameters:\", grid_search.best_params_)\n"
      ],
      "metadata": {
        "id": "Saw9D0sdCH97"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RF=RandomForestClassifier()\n",
        "DT=DecisionTreeClassifier()\n",
        "\n"
      ],
      "metadata": {
        "id": "L_-ZzM57kUYH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_DT = {'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
        "param_RF = {'n_estimators': [50, 100, 150, 200], 'max_depth': [3, 5, 7], 'min_samples_split': [3, 5, 7], 'min_samples_leaf': [16, 32]}"
      ],
      "metadata": {
        "id": "oDfPL6-wkY9S"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models_params = [\n",
        "    (DT, param_DT),\n",
        "    (RF, param_RF),\n",
        "\n",
        "]\n",
        "\n",
        "ngram_range = [(1, 2), (1, 3)]\n",
        "max_features = [500, 1000, 2000, 3000, 4000, 5000]\n",
        "vectorizers = [CountVectorizer, TfidfVectorizer]\n",
        "\n",
        "\n",
        "for model, model_params in models_params:\n",
        "    for vec in vectorizers:\n",
        "        for ngram in ngram_range:\n",
        "            for max_feat in max_features:\n",
        "                train_model(model, model_params, vec, ngram, max_feat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkfsC-0xkbW8",
        "outputId": "d1816a34-f8cc-46b7-cdb0-1f4d91727bc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Name: DecisionTreeClassifier \n",
            " Ngram Range: (1, 2) \n",
            " Max Features: 500 \n",
            " Vectorizer: CountVectorizer \n",
            " Accuracy: 0.7169333333333333\n",
            "Best parameters: {'max_depth': 10}\n",
            "Model Name: DecisionTreeClassifier \n",
            " Ngram Range: (1, 2) \n",
            " Max Features: 1000 \n",
            " Vectorizer: CountVectorizer \n",
            " Accuracy: 0.7197333333333333\n",
            "Best parameters: {'max_depth': 10}\n",
            "Model Name: DecisionTreeClassifier \n",
            " Ngram Range: (1, 2) \n",
            " Max Features: 2000 \n",
            " Vectorizer: CountVectorizer \n",
            " Accuracy: 0.7272\n",
            "Best parameters: {'max_depth': 10}\n",
            "Model Name: DecisionTreeClassifier \n",
            " Ngram Range: (1, 2) \n",
            " Max Features: 3000 \n",
            " Vectorizer: CountVectorizer \n",
            " Accuracy: 0.7265333333333334\n",
            "Best parameters: {'max_depth': 10}\n",
            "Model Name: DecisionTreeClassifier \n",
            " Ngram Range: (1, 2) \n",
            " Max Features: 4000 \n",
            " Vectorizer: CountVectorizer \n",
            " Accuracy: 0.7257333333333333\n",
            "Best parameters: {'max_depth': 10}\n",
            "Model Name: DecisionTreeClassifier \n",
            " Ngram Range: (1, 2) \n",
            " Max Features: 5000 \n",
            " Vectorizer: CountVectorizer \n",
            " Accuracy: 0.7270666666666666\n",
            "Best parameters: {'max_depth': 10}\n",
            "Model Name: DecisionTreeClassifier \n",
            " Ngram Range: (1, 3) \n",
            " Max Features: 500 \n",
            " Vectorizer: CountVectorizer \n",
            " Accuracy: 0.7138666666666666\n",
            "Best parameters: {'max_depth': 9}\n",
            "Model Name: DecisionTreeClassifier \n",
            " Ngram Range: (1, 3) \n",
            " Max Features: 1000 \n",
            " Vectorizer: CountVectorizer \n",
            " Accuracy: 0.7218666666666667\n",
            "Best parameters: {'max_depth': 10}\n",
            "Model Name: DecisionTreeClassifier \n",
            " Ngram Range: (1, 3) \n",
            " Max Features: 2000 \n",
            " Vectorizer: CountVectorizer \n",
            " Accuracy: 0.7258666666666667\n",
            "Best parameters: {'max_depth': 10}\n",
            "Model Name: DecisionTreeClassifier \n",
            " Ngram Range: (1, 3) \n",
            " Max Features: 3000 \n",
            " Vectorizer: CountVectorizer \n",
            " Accuracy: 0.726\n",
            "Best parameters: {'max_depth': 10}\n",
            "Model Name: DecisionTreeClassifier \n",
            " Ngram Range: (1, 3) \n",
            " Max Features: 4000 \n",
            " Vectorizer: CountVectorizer \n",
            " Accuracy: 0.726\n",
            "Best parameters: {'max_depth': 10}\n",
            "Model Name: DecisionTreeClassifier \n",
            " Ngram Range: (1, 3) \n",
            " Max Features: 5000 \n",
            " Vectorizer: CountVectorizer \n",
            " Accuracy: 0.7278666666666667\n",
            "Best parameters: {'max_depth': 10}\n",
            "Model Name: DecisionTreeClassifier \n",
            " Ngram Range: (1, 2) \n",
            " Max Features: 500 \n",
            " Vectorizer: TfidfVectorizer \n",
            " Accuracy: 0.702\n",
            "Best parameters: {'max_depth': 10}\n",
            "Model Name: DecisionTreeClassifier \n",
            " Ngram Range: (1, 2) \n",
            " Max Features: 1000 \n",
            " Vectorizer: TfidfVectorizer \n",
            " Accuracy: 0.7190666666666666\n",
            "Best parameters: {'max_depth': 9}\n",
            "Model Name: DecisionTreeClassifier \n",
            " Ngram Range: (1, 2) \n",
            " Max Features: 2000 \n",
            " Vectorizer: TfidfVectorizer \n",
            " Accuracy: 0.7244\n",
            "Best parameters: {'max_depth': 10}\n",
            "Model Name: DecisionTreeClassifier \n",
            " Ngram Range: (1, 2) \n",
            " Max Features: 3000 \n",
            " Vectorizer: TfidfVectorizer \n",
            " Accuracy: 0.7212\n",
            "Best parameters: {'max_depth': 10}\n",
            "Model Name: DecisionTreeClassifier \n",
            " Ngram Range: (1, 2) \n",
            " Max Features: 4000 \n",
            " Vectorizer: TfidfVectorizer \n",
            " Accuracy: 0.7252\n",
            "Best parameters: {'max_depth': 10}\n",
            "Model Name: DecisionTreeClassifier \n",
            " Ngram Range: (1, 2) \n",
            " Max Features: 5000 \n",
            " Vectorizer: TfidfVectorizer \n",
            " Accuracy: 0.7253333333333334\n",
            "Best parameters: {'max_depth': 10}\n",
            "Model Name: DecisionTreeClassifier \n",
            " Ngram Range: (1, 3) \n",
            " Max Features: 500 \n",
            " Vectorizer: TfidfVectorizer \n",
            " Accuracy: 0.7022666666666667\n",
            "Best parameters: {'max_depth': 10}\n",
            "Model Name: DecisionTreeClassifier \n",
            " Ngram Range: (1, 3) \n",
            " Max Features: 1000 \n",
            " Vectorizer: TfidfVectorizer \n",
            " Accuracy: 0.7201333333333333\n",
            "Best parameters: {'max_depth': 10}\n",
            "Model Name: DecisionTreeClassifier \n",
            " Ngram Range: (1, 3) \n",
            " Max Features: 2000 \n",
            " Vectorizer: TfidfVectorizer \n",
            " Accuracy: 0.7261333333333333\n",
            "Best parameters: {'max_depth': 10}\n",
            "Model Name: DecisionTreeClassifier \n",
            " Ngram Range: (1, 3) \n",
            " Max Features: 3000 \n",
            " Vectorizer: TfidfVectorizer \n",
            " Accuracy: 0.7212\n",
            "Best parameters: {'max_depth': 10}\n",
            "Model Name: DecisionTreeClassifier \n",
            " Ngram Range: (1, 3) \n",
            " Max Features: 4000 \n",
            " Vectorizer: TfidfVectorizer \n",
            " Accuracy: 0.7209333333333333\n",
            "Best parameters: {'max_depth': 10}\n",
            "Model Name: DecisionTreeClassifier \n",
            " Ngram Range: (1, 3) \n",
            " Max Features: 5000 \n",
            " Vectorizer: TfidfVectorizer \n",
            " Accuracy: 0.7228\n",
            "Best parameters: {'max_depth': 10}\n",
            "Model Name: RandomForestClassifier \n",
            " Ngram Range: (1, 2) \n",
            " Max Features: 500 \n",
            " Vectorizer: CountVectorizer \n",
            " Accuracy: 0.7794666666666666\n",
            "Best parameters: {'max_depth': 7, 'min_samples_leaf': 32, 'min_samples_split': 7, 'n_estimators': 150}\n",
            "Model Name: RandomForestClassifier \n",
            " Ngram Range: (1, 2) \n",
            " Max Features: 1000 \n",
            " Vectorizer: CountVectorizer \n",
            " Accuracy: 0.7969333333333334\n",
            "Best parameters: {'max_depth': 7, 'min_samples_leaf': 16, 'min_samples_split': 7, 'n_estimators': 150}\n",
            "Model Name: RandomForestClassifier \n",
            " Ngram Range: (1, 2) \n",
            " Max Features: 2000 \n",
            " Vectorizer: CountVectorizer \n",
            " Accuracy: 0.8125333333333333\n",
            "Best parameters: {'max_depth': 7, 'min_samples_leaf': 16, 'min_samples_split': 3, 'n_estimators': 150}\n",
            "Model Name: RandomForestClassifier \n",
            " Ngram Range: (1, 2) \n",
            " Max Features: 3000 \n",
            " Vectorizer: CountVectorizer \n",
            " Accuracy: 0.8136\n",
            "Best parameters: {'max_depth': 7, 'min_samples_leaf': 32, 'min_samples_split': 3, 'n_estimators': 150}\n",
            "Model Name: RandomForestClassifier \n",
            " Ngram Range: (1, 2) \n",
            " Max Features: 4000 \n",
            " Vectorizer: CountVectorizer \n",
            " Accuracy: 0.8068\n",
            "Best parameters: {'max_depth': 7, 'min_samples_leaf': 32, 'min_samples_split': 5, 'n_estimators': 200}\n",
            "Model Name: RandomForestClassifier \n",
            " Ngram Range: (1, 2) \n",
            " Max Features: 5000 \n",
            " Vectorizer: CountVectorizer \n",
            " Accuracy: 0.8190666666666667\n",
            "Best parameters: {'max_depth': 7, 'min_samples_leaf': 16, 'min_samples_split': 3, 'n_estimators': 150}\n",
            "Model Name: RandomForestClassifier \n",
            " Ngram Range: (1, 3) \n",
            " Max Features: 500 \n",
            " Vectorizer: CountVectorizer \n",
            " Accuracy: 0.7769333333333334\n",
            "Best parameters: {'max_depth': 7, 'min_samples_leaf': 16, 'min_samples_split': 5, 'n_estimators': 200}\n",
            "Model Name: RandomForestClassifier \n",
            " Ngram Range: (1, 3) \n",
            " Max Features: 1000 \n",
            " Vectorizer: CountVectorizer \n",
            " Accuracy: 0.7964\n",
            "Best parameters: {'max_depth': 7, 'min_samples_leaf': 16, 'min_samples_split': 3, 'n_estimators': 200}\n",
            "Model Name: RandomForestClassifier \n",
            " Ngram Range: (1, 3) \n",
            " Max Features: 2000 \n",
            " Vectorizer: CountVectorizer \n",
            " Accuracy: 0.8076\n",
            "Best parameters: {'max_depth': 7, 'min_samples_leaf': 16, 'min_samples_split': 3, 'n_estimators': 150}\n",
            "Model Name: RandomForestClassifier \n",
            " Ngram Range: (1, 3) \n",
            " Max Features: 3000 \n",
            " Vectorizer: CountVectorizer \n",
            " Accuracy: 0.8141333333333334\n",
            "Best parameters: {'max_depth': 7, 'min_samples_leaf': 16, 'min_samples_split': 3, 'n_estimators': 200}\n",
            "Model Name: RandomForestClassifier \n",
            " Ngram Range: (1, 3) \n",
            " Max Features: 4000 \n",
            " Vectorizer: CountVectorizer \n",
            " Accuracy: 0.8102666666666667\n",
            "Best parameters: {'max_depth': 7, 'min_samples_leaf': 32, 'min_samples_split': 7, 'n_estimators': 200}\n",
            "Model Name: RandomForestClassifier \n",
            " Ngram Range: (1, 3) \n",
            " Max Features: 5000 \n",
            " Vectorizer: CountVectorizer \n",
            " Accuracy: 0.8162666666666667\n",
            "Best parameters: {'max_depth': 7, 'min_samples_leaf': 16, 'min_samples_split': 5, 'n_estimators': 200}\n",
            "Model Name: RandomForestClassifier \n",
            " Ngram Range: (1, 2) \n",
            " Max Features: 500 \n",
            " Vectorizer: TfidfVectorizer \n",
            " Accuracy: 0.7764\n",
            "Best parameters: {'max_depth': 7, 'min_samples_leaf': 16, 'min_samples_split': 5, 'n_estimators': 150}\n",
            "Model Name: RandomForestClassifier \n",
            " Ngram Range: (1, 2) \n",
            " Max Features: 1000 \n",
            " Vectorizer: TfidfVectorizer \n",
            " Accuracy: 0.7989333333333334\n",
            "Best parameters: {'max_depth': 7, 'min_samples_leaf': 32, 'min_samples_split': 3, 'n_estimators': 200}\n",
            "Model Name: RandomForestClassifier \n",
            " Ngram Range: (1, 2) \n",
            " Max Features: 2000 \n",
            " Vectorizer: TfidfVectorizer \n",
            " Accuracy: 0.8076\n",
            "Best parameters: {'max_depth': 7, 'min_samples_leaf': 16, 'min_samples_split': 5, 'n_estimators': 150}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saeYMw5HtkU2"
      },
      "source": [
        "Qwen and Zephyr can't be done on local machines (specially laptops) and should be done on Cloud"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}