{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from transformers.generation import GenerationConfig\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import textwrap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solving class example using Qwen LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using PLM (bert-finetune-sst2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Qwen to evaluate all the 8 comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading IMDB dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SAPS AT SEA &lt;br /&gt;&lt;br /&gt;Aspect ratio: 1.37:1&lt;b...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>If you want mindless action, hot chicks and a ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"The Woman in Black\" is easily one of the cree...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I can barely find the words to describe how mu...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What's in here ?! Let me tell you. It's the pr...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  SAPS AT SEA <br /><br />Aspect ratio: 1.37:1<b...  negative\n",
       "1  If you want mindless action, hot chicks and a ...  positive\n",
       "2  \"The Woman in Black\" is easily one of the cree...  positive\n",
       "3  I can barely find the words to describe how mu...  negative\n",
       "4  What's in here ?! Let me tell you. It's the pr...  negative"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os   \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\"\"\" # load the dataset\n",
    "with open('corpus.txt','r',encoding=\"utf8\") as f:\n",
    "    document = f.readlines()\n",
    "f.close()\n",
    "\n",
    "labels, texts = [], []\n",
    "for line in document:\n",
    "    content = line.split()\n",
    "    label = content[0]\n",
    "    labels.append(label[-1])\n",
    "    texts.append(\" \".join(content[1:]))\n",
    "\n",
    "print(len(labels), len(texts)) \"\"\"\n",
    "\n",
    "os.chdir(\"D:/Semesters/Spring 24/Introduction to Text Analytics/Assignment-2\")\n",
    "df=pd.read_csv(\"train.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0} SAPS AT SEA <br /><br />Aspect ratio: 1.37:1<br /><br />Sound format: Mono<br /><br />(Black and white)<br /><br />Suffering from 'hornophobia', Ollie embarks on a 'restful' boat trip, but he and Stan get mixed up with an escaped convict (Rychard Cramer). Chaos ensues.<br /><br />This feature length comedy - an OK entry which nonetheless unspools like a mere imitation of Laurel and Hardy's best work - marked the final collaboration between L&H and producer Hal Roach. Episodic in structure, the movie culminates in a memorable ocean voyage after The Boys are taken hostage by villainous Cramer (who shoots a seagull to prove how tough he is!). The gags are OK, but inspiration is lacking, perhaps due to the recruitment of actor-turned-director Gordon Douglas, previously responsible for Ollie's first solo effort in the sound era (ZENOBIA, produced in 1939), but whose work here lacks a measure of pzazz. Fair, but nothing special. L&H regulars Charlie Hall and James Finlayson make guest appearances. \n",
      "\n",
      "{1} If you want mindless action, hot chicks and a post-apocalyptic view of Seattle, then this is the show for you!<br /><br />The concept of Dark Angel isn't anything new (in fact, there's controversy over whether James Cameron stole the idea from a book), but I spend the entire hour watching it every Tuesday from start to finish.<br /><br />Jessica Alba is smoking and Max' friends (original Cindy, Kendra) are just as hot. <br /><br />The fight scenes are getting better, but the dialogues between Original Cindy and Max need to be a little bit better (the slang sounds forced and it sounds like someone living in the suburbs wrote it).<br /><br />In my opinion, Dark Angel is a great guilty pleasure filled with everything an action fan could ask for, but if you're looking for hard hitting, award-winning drama, go watch \"The West Wing\" or something. \n",
      "\n",
      "{2} \"The Woman in Black\" is easily one of the creepiest British ghost stories ever made.A young solicitor,after arriving in a small town to handle a dead client's estate,is haunted by a mysterious woman dressed all in black.The film is loaded with extremely eerie atmosphere and the frights are calculated for and deliver the maximum effect possible.The action keeps the viewer deeply involved and the finale is quite disturbing.The acting is excellent and the tension is almost unbearable at times.So if you want to see a truly creepy horror film give this one a look.I dare anyone to watch \"The Woman in Black\" alone at night with the lights off.Highly recommended.10 out of 10. \n",
      "\n",
      "{3} I can barely find the words to describe how much this piece of trash offended me. Why is it that American filmmakers always go out of there way to portray Jamaicans as a bunch of backwards ass bush babies and worse yet, cast people to play Jamaicans who sound utterly ridiculous when they try to imitate the accent? We are not all extremely dark, we do not all walk around carrying machetes whether for work OR PROTECTION, we do not walk around naked in our homes and we do not practice VOODOO!! We are doctors, lawyers, architects, Businessmen and women, musicians, actors AND FILMMAKERS. I am sick and tired of watching all of these portrayals of Jamaicans as a bunch of dreadlock wearing Rastafarians who do nothing but sit around all day smoking weed on a beach or shooting guns in the air (When we're not living in our tree houses). YES, we wear clothes. YES, we have electricity. No, weed is not legal on the island AND CHANCES ARE WE SPEAK BETTER English THAN YOU! The worst part is, this isn't just me being angry and bitter, these are actual answers to questions that most Jamaicans who have traveled overseas have been asked at some point. Read a book before you assume what's it's like in another country and worse yet, decide to make a movie about it.<br /><br />WELCOME TO JAMAICA! The land where all we do is murder white people and beat our bongos drums...Tales from the Crypt has officially sickened me, along with the entire crew of people who worked on this garbage, especially the writer. \n",
      "\n",
      "{4} What's in here ?! Let me tell you. It's the presence of (Alec Baldwin). He's not a great actor but maybe a nice star with some good movies which this is not one of them. He did nothing here more than anything he did before or after. So not to mention (literally !) the matter of (Steve McQueen) being at the same role in the original because I don't want to make that comparison in the first place. I'm not a big fan or even a fan of (Kim Basinger), she got a lot of bad movies on her and even at her best she looks average ! And it gets on my nerve indeed whenever they talk about her seductive rare beauty !!?? Well, if being a blond would make anyone captivating then I'll dye my hair in yellow as soon as possible ! And what is it with all the craziness over miss Basinger's Legs ??!! It's surely insanity or bad tasting ? As I don't see them both as not sexy only, but UGLY too ! And if you hate that so shoot me down but you know what ?! I've just watched this movie so I'm dead already !. Yet, what would make you really suffer in unbearable way is that nothing of the credits goes to the one she deserves the mostÂ…And of course I mean (Jennifer Tilly)..Now we're talking about a true genuine seductive chick with such unforgettable body and one unique sense of allurement like a nasty brunette (Marilyn Monroe) however much more healthier !! (I can't help it, she was the only new and watchable thing in here !). (Michael Madsen) as the bad guy was much appealing as well as effective more than the good guys, (James Woods) is here to summarize the early events beside the pool (so the trailer would be by his voice later !) and he knew before all that this is a whole Hollywood's stuff so \"Do your thing, take your cash, and good luck as an actor in other movies !\", the editing gave the movie a serious personality along with violent atmosphere done by suitable shining cinematography, so the main goods of it (The action, The thrill, ..) are here and fairly well-made, though any echo for deep meanings about (the kinds of betrayal) as the main dramatic motif of the whole thing is not that strong so don't wait for it. OK, it's all in all another remake without anything special (Except Jennifer Tilly's spicy moments !) so I think I tried to be objective as much as I could therefore I shouldn't end my review saying that (Basinger) or anyone here did better than this movie.. It would be an insult because frankly.. Anything is better than this movie! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,5):\n",
    "  print({i},df.iloc[i]['review'],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    negative\n",
       "1    positive\n",
       "2    positive\n",
       "3    negative\n",
       "4    negative\n",
       "5    negative\n",
       "6    positive\n",
       "7    negative\n",
       "8    negative\n",
       "9    negative\n",
       "Name: sentiment, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0:10]['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing BoW using CountVectorizer and TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCTION FOR TRAINING MODEL TO AVOID REPETITION DIVIDED MY WORK INTO THREE NOTEBOOKS ONE RUNNING ON COLAB ONE ON KAGGLE AND ONE ON MY LOCAL MACHINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, param_grid, vectorizer, ngram_range, max_features):\n",
    "    cnt_vectorizer = vectorizer(ngram_range=ngram_range, max_features=max_features)\n",
    "    features = cnt_vectorizer.fit_transform(df['review'])\n",
    "    features_nd = features.toarray()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features_nd, df['sentiment'], train_size=0.75, random_state=1234)\n",
    "    \n",
    "    grid_search = GridSearchCV(model, param_grid, cv=3)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    print(\"Model Name:\", model.__class__.__name__, \"\\n\", \"Ngram Range:\", ngram_range, \"\\n\", \"Max Features:\", max_features, \"\\n\", \"Vectorizer:\", vectorizer.__name__, \"\\n\", \"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(\"Best parameters:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THESE ARE THE MODELS I EXPERIMENTED WITH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB=GradientBoostingClassifier()\n",
    "RF=RandomForestClassifier()\n",
    "DT=DecisionTreeClassifier()\n",
    "KNN=KNeighborsClassifier()\n",
    "MNB=MultinomialNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 500 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.7637333333333334\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 1000 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.7957333333333333\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 2000 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.8214666666666667\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 3000 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.8272\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 4000 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.8369333333333333\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 5000 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.8425333333333334\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 500 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.7609333333333334\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 1000 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.7944\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 2000 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.8213333333333334\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 3000 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.8257333333333333\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 4000 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.8348\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 5000 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.8409333333333333\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 500 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.7970666666666667\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 1000 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.8318666666666666\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 2000 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.8462666666666666\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 3000 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.8525333333333334\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 4000 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.8601333333333333\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 5000 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.8622666666666666\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 500 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.7969333333333334\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 1000 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.83\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 2000 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.8468\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 3000 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.8482666666666666\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 4000 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.8550666666666666\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 5000 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.8616\n",
      "Best parameters: {}\n"
     ]
    }
   ],
   "source": [
    "param_KNN = {'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "param_DT = {'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}\n",
    "param_RF = {'n_estimators': [50, 100, 150, 200], 'max_depth': [3, 5, 7], 'min_samples_split': [3, 5, 7], 'min_samples_leaf': [16, 32]}\n",
    "param_GB = {'n_estimators': [50, 100, 150, 200], 'max_depth': [3, 5, 7], 'min_samples_split': [3, 5, 7], 'min_samples_leaf': [16, 32]}\n",
    "\n",
    "\n",
    "models_params = [\n",
    "\n",
    "    (MNB, {})  \n",
    "]\n",
    "\n",
    "ngram_range = [(1, 2), (1, 3)]\n",
    "max_features = [500, 1000, 2000, 3000, 4000, 5000]\n",
    "vectorizers = [CountVectorizer, TfidfVectorizer]\n",
    "\n",
    "\n",
    "for model, model_params in models_params:\n",
    "    for vec in vectorizers:\n",
    "        for ngram in ngram_range:\n",
    "            for max_feat in max_features:\n",
    "                train_model(model, model_params, vec, ngram, max_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: KNeighborsClassifier \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 500 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.6325333333333333\n",
      "Best parameters: {'n_neighbors': 9}\n",
      "Model Name: KNeighborsClassifier \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 1000 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.6321333333333333\n",
      "Best parameters: {'n_neighbors': 9}\n",
      "Model Name: KNeighborsClassifier \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 2000 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.6314666666666666\n",
      "Best parameters: {'n_neighbors': 9}\n",
      "Model Name: KNeighborsClassifier \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 3000 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.6297333333333334\n",
      "Best parameters: {'n_neighbors': 9}\n",
      "Model Name: KNeighborsClassifier \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 4000 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.6230666666666667\n",
      "Best parameters: {'n_neighbors': 9}\n",
      "Model Name: KNeighborsClassifier \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 5000 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.6257333333333334\n",
      "Best parameters: {'n_neighbors': 9}\n",
      "Model Name: KNeighborsClassifier \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 500 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.6338666666666667\n",
      "Best parameters: {'n_neighbors': 9}\n",
      "Model Name: KNeighborsClassifier \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 1000 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.6324\n",
      "Best parameters: {'n_neighbors': 9}\n",
      "Model Name: KNeighborsClassifier \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 2000 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.6282666666666666\n",
      "Best parameters: {'n_neighbors': 9}\n",
      "Model Name: KNeighborsClassifier \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 3000 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.6297333333333334\n",
      "Best parameters: {'n_neighbors': 9}\n",
      "Model Name: KNeighborsClassifier \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 4000 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.6268\n",
      "Best parameters: {'n_neighbors': 9}\n",
      "Model Name: KNeighborsClassifier \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 5000 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.6222666666666666\n",
      "Best parameters: {'n_neighbors': 9}\n",
      "Model Name: KNeighborsClassifier \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 500 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.6957333333333333\n",
      "Best parameters: {'n_neighbors': 9}\n",
      "Model Name: KNeighborsClassifier \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 1000 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.6992\n",
      "Best parameters: {'n_neighbors': 9}\n",
      "Model Name: KNeighborsClassifier \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 2000 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.6885333333333333\n",
      "Best parameters: {'n_neighbors': 9}\n",
      "Model Name: KNeighborsClassifier \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 3000 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.6929333333333333\n",
      "Best parameters: {'n_neighbors': 9}\n",
      "Model Name: KNeighborsClassifier \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 4000 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.6928\n",
      "Best parameters: {'n_neighbors': 9}\n",
      "Model Name: KNeighborsClassifier \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 5000 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.6944\n",
      "Best parameters: {'n_neighbors': 9}\n",
      "Model Name: KNeighborsClassifier \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 500 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.6918666666666666\n",
      "Best parameters: {'n_neighbors': 9}\n",
      "Model Name: KNeighborsClassifier \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 1000 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.6950666666666667\n",
      "Best parameters: {'n_neighbors': 9}\n",
      "Model Name: KNeighborsClassifier \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 2000 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.6917333333333333\n",
      "Best parameters: {'n_neighbors': 9}\n",
      "Model Name: KNeighborsClassifier \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 3000 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.6944\n",
      "Best parameters: {'n_neighbors': 9}\n",
      "Model Name: KNeighborsClassifier \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 4000 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.6958666666666666\n",
      "Best parameters: {'n_neighbors': 9}\n",
      "Model Name: KNeighborsClassifier \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 5000 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.6961333333333334\n",
      "Best parameters: {'n_neighbors': 9}\n"
     ]
    }
   ],
   "source": [
    "param_KNN = {'n_neighbors': [1,  3,  5,  7, 9]}\n",
    "models_params = [\n",
    "\n",
    "    (KNN, param_KNN)  \n",
    "]\n",
    "\n",
    "ngram_range = [(1, 2), (1, 3)]\n",
    "max_features = [500, 1000, 2000, 3000, 4000, 5000]\n",
    "vectorizers = [CountVectorizer, TfidfVectorizer]\n",
    "\n",
    "\n",
    "for model, model_params in models_params:\n",
    "    for vec in vectorizers:\n",
    "        for ngram in ngram_range:\n",
    "            for max_feat in max_features:\n",
    "                train_model(model, model_params, vec, ngram, max_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APPLYING STEMMING AND STOPWORD REMOVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "df=pd.read_csv(\"train.csv\")\n",
    "df.head()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.add('.')\n",
    "stop_words.add('<')\n",
    "stop_words.add('>')\n",
    "stop_words.add('?')\n",
    "stop_words.add('br')\n",
    "stop_words.add('/')\n",
    "stop_words.add('.')\n",
    "\n",
    "for i in range(len(df['review'])):\n",
    "\tword_tokens = word_tokenize(df['review'][i])\n",
    "\tfiltered_sentence = [w for w in word_tokens if not w in stop_words and w != ',']\n",
    "\tfiltered_sentence = []\n",
    "\tfor w in word_tokens:\n",
    "\t\tif w not in stop_words and w != ',':\n",
    "\t\t\tfiltered_sentence.append(w)\n",
    "\tdf['review'][i] = ' '.join(filtered_sentence)\n",
    "\tdf['review'][i] = df['review'][i].lower()\n",
    "\t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0} sap at sea aspect ratio : 1.37:1 sound format : mono ( black white ) suffer 'hornophobia ' olli embark 'rest ' boat trip stan get mix escap convict ( rychard cramer ) chao ensu . thi featur length comedi - ok entri nonetheless unspool like mere imit laurel hardi 's best work - mark final collabor l & h produc hal roach episod structur movi culmin memor ocean voyag the boy taken hostag villain cramer ( shoot seagul prove tough ! ) the gag ok inspir lack perhap due recruit actor-turned-director gordon dougla previous respons olli 's first solo effort sound era ( zenobia produc 1939 ) whose work lack measur pzazz fair noth special l & h regular charli hall jame finlayson make guest appear \n",
      "\n",
      "{1} if want mindless action hot chick post-apocalypt view seattl show ! the concept dark angel n't anyth new ( fact 's controversi whether jame cameron stole idea book ) i spend entir hour watch everi tuesday start finish . jessica alba smoke max ' friend ( origin cindi kendra ) hot the fight scene get better dialogu origin cindi max need littl bit better ( slang sound forc sound like someon live suburb wrote ) in opinion dark angel great guilti pleasur fill everyth action fan could ask 're look hard hit award-win drama go watch `` the west wing `` someth \n",
      "\n",
      "{2} `` the woman black `` easili one creepiest british ghost stori ever made.a young solicitor arriv small town handl dead client 's estat haunt mysteri woman dress black.th film load extrem eeri atmospher fright calcul deliv maximum effect possible.th action keep viewer deepli involv final quit disturbing.th act excel tension almost unbear times.so want see truli creepi horror film give one look.i dare anyon watch `` the woman black `` alon night light off.highli recommended.10 10 \n",
      "\n",
      "{3} i bare find word describ much piec trash offend whi american filmmak alway go way portray jamaican bunch backward ass bush babi wors yet cast peopl play jamaican sound utterli ridicul tri imit accent we extrem dark walk around carri machet whether work or protect walk around nake home practic voodoo ! ! we doctor lawyer architect businessmen women musician actor and filmmak i sick tire watch portray jamaican bunch dreadlock wear rastafarian noth sit around day smoke weed beach shoot gun air ( when 're live tree hous ) ye wear cloth ye electr no weed legal island and chanc are we speak better english than you ! the worst part n't angri bitter actual answer question jamaican travel oversea ask point read book assum 's 's like anoth countri wors yet decid make movi it . welcom to jamaica ! the land murder white peopl beat bongo drum ... tale crypt offici sicken along entir crew peopl work garbag especi writer \n",
      "\n",
      "{4} what 's ! let tell it 's presenc ( alec baldwin ) he 's great actor mayb nice star good movi one he noth anyth so mention ( liter ! ) matter ( steve mcqueen ) role origin i n't want make comparison first place i 'm big fan even fan ( kim basing ) got lot bad movi even best look averag ! and get nerv inde whenev talk seduct rare beauti ! ! well blond would make anyon captiv i 'll dye hair yellow soon possibl ! and crazi miss basing 's leg ! ! it 's sure insan bad tast as i n't see sexi ugli ! and hate shoot know ! i 've watch movi i 'm dead alreadi ! yet would make realli suffer unbear way noth credit goe one deserv and cours i mean ( jennif tilli ) .. now 're talk true genuin seduct chick unforgett bodi one uniqu sens allur like nasti brunett ( marilyn monro ) howev much healthier ! ! ( i ca n't help new watchabl thing ! ) ( michael madsen ) bad guy much appeal well effect good guy ( jame wood ) summar earli event besid pool ( trailer would voic later ! ) knew whole hollywood 's stuff `` do thing take cash good luck actor movi ! `` edit gave movi seriou person along violent atmospher done suitabl shine cinematographi main good ( the action the thrill .. ) fairli well-mad though echo deep mean ( kind betray ) main dramat motif whole thing strong n't wait ok 's anoth remak without anyth special ( except jennif tilli 's spici moment ! ) i think i tri object much i could therefor i n't end review say ( basing ) anyon better movi .. it would insult frankli .. anyth better movi ! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "stem=PorterStemmer()\n",
    "for i in range(len(df['review'])):\n",
    "    words = word_tokenize(df['review'][i])\n",
    "    words = [stem.stem(word) for word in words]\n",
    "    df['review'][i] = ' '.join(words)\n",
    "for i in range (0,5):\n",
    "   print({i},df.iloc[i]['review'],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 500 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.82\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 1000 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.8304\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 2000 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.8398666666666667\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 3000 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.8457333333333333\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 4000 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.8465333333333334\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 5000 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.8498666666666667\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 500 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.82\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 1000 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.8304\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 2000 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.8397333333333333\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 3000 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.8462666666666666\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 4000 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.8444\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 5000 \n",
      " Vectorizer: CountVectorizer \n",
      " Accuracy: 0.848\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 500 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.8257333333333333\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 1000 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.8357333333333333\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 2000 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.8437333333333333\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 3000 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.8529333333333333\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 4000 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.8541333333333333\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 2) \n",
      " Max Features: 5000 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.8549333333333333\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 500 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.8257333333333333\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 1000 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.8357333333333333\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 2000 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.8433333333333334\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 3000 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.8510666666666666\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 4000 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.8526666666666667\n",
      "Best parameters: {}\n",
      "Model Name: MultinomialNB \n",
      " Ngram Range: (1, 3) \n",
      " Max Features: 5000 \n",
      " Vectorizer: TfidfVectorizer \n",
      " Accuracy: 0.8532\n",
      "Best parameters: {}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "models_params = [\n",
    "\n",
    "    (MNB, {})  \n",
    "]\n",
    "\n",
    "ngram_range = [(1, 2), (1, 3)]\n",
    "max_features = [500, 1000, 2000, 3000, 4000, 5000]\n",
    "vectorizers = [CountVectorizer, TfidfVectorizer]\n",
    "\n",
    "\n",
    "for model, model_params in models_params:\n",
    "    for vec in vectorizers:\n",
    "        for ngram in ngram_range:\n",
    "            for max_feat in max_features:\n",
    "                train_model(model, model_params, vec, ngram, max_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF_Stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8273333333333334\n"
     ]
    }
   ],
   "source": [
    "RF=RandomForestClassifier(max_depth=7,min_samples_leaf=16,min_samples_split=5,n_estimators=200)\n",
    "cnt_vectorizer = CountVectorizer(ngram_range=(1, 3), max_features=5000)\n",
    "features = cnt_vectorizer.fit_transform(df['review'])\n",
    "features_nd = features.toarray()\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_nd, df['sentiment'], train_size=0.75, random_state=1234)\n",
    "RF.fit(features_nd, df['sentiment'])\n",
    "y_pred = RF.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GB_Stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8821333333333333\n"
     ]
    }
   ],
   "source": [
    "RF=GradientBoostingClassifier(max_depth=5,min_samples_leaf=32,min_samples_split=3,n_estimators=200)\n",
    "cnt_vectorizer = CountVectorizer(ngram_range=(1, 2), max_features=500)\n",
    "features = cnt_vectorizer.fit_transform(df['review'])\n",
    "features_nd = features.toarray()\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_nd, df['sentiment'], train_size=0.75, random_state=1234)\n",
    "RF.fit(features_nd, df['sentiment'])\n",
    "y_pred = RF.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN_Stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8138666666666666\n"
     ]
    }
   ],
   "source": [
    "RF=KNeighborsClassifier(n_neighbors=9)\n",
    "cnt_vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=1000)\n",
    "features = cnt_vectorizer.fit_transform(df['review'])\n",
    "features_nd = features.toarray()\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_nd, df['sentiment'], train_size=0.75, random_state=1234)\n",
    "RF.fit(features_nd, df['sentiment'])\n",
    "y_pred = RF.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "APPLYING LEMMATIZATION ONLY FOR MULTINOMIAL NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "df=pd.read_csv(\"train.csv\")\n",
    "df.head()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.add('.')\n",
    "stop_words.add('<')\n",
    "stop_words.add('>')\n",
    "stop_words.add('?')\n",
    "stop_words.add('br')\n",
    "stop_words.add('/')\n",
    "stop_words.add('.')\n",
    "\n",
    "for i in range(len(df['review'])):\n",
    "\tword_tokens = word_tokenize(df['review'][i])\n",
    "\tfiltered_sentence = [w for w in word_tokens if not w in stop_words and w != ',']\n",
    "\tfiltered_sentence = []\n",
    "\tfor w in word_tokens:\n",
    "\t\tif w not in stop_words and w != ',':\n",
    "\t\t\tfiltered_sentence.append(w)\n",
    "\tdf['review'][i] = ' '.join(filtered_sentence)\n",
    "\tdf['review'][i] = df['review'][i].lower()\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "for i in range(len(df['review'])):\n",
    "    words = word_tokenize(df['review'][i])\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    df['review'][i] = ' '.join(words)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_params = [\n",
    "\n",
    "    (MNB, {})  \n",
    "]\n",
    "\n",
    "ngram_range = [(1, 2), (1, 3)]\n",
    "max_features = [500, 1000, 2000, 3000, 4000, 5000]\n",
    "vectorizers = [CountVectorizer, TfidfVectorizer]\n",
    "\n",
    "\n",
    "for model, model_params in models_params:\n",
    "    for vec in vectorizers:\n",
    "        for ngram in ngram_range:\n",
    "            for max_feat in max_features:\n",
    "                train_model(model, model_params, vec, ngram, max_feat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEMMATIZED RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8278666666666666\n"
     ]
    }
   ],
   "source": [
    "RF=RandomForestClassifier(max_depth=7,min_samples_leaf=16,min_samples_split=5,n_estimators=200)\n",
    "cnt_vectorizer = CountVectorizer(ngram_range=(1, 3), max_features=5000)\n",
    "features = cnt_vectorizer.fit_transform(df['review'])\n",
    "features_nd = features.toarray()\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_nd, df['sentiment'], train_size=0.75, random_state=1234)\n",
    "RF.fit(features_nd, df['sentiment'])\n",
    "y_pred = RF.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LEMMATIZED DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7689333333333334\n"
     ]
    }
   ],
   "source": [
    "DT=DecisionTreeClassifier(max_depth=10)\n",
    "cnt_vectorizer = TfidfVectorizer(ngram_range=(1, 3), max_features=2000)\n",
    "features = cnt_vectorizer.fit_transform(df['review'])\n",
    "features_nd = features.toarray()\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_nd, df['sentiment'], train_size=0.75, random_state=1234)\n",
    "DT.fit(features_nd, df['sentiment'])\n",
    "y_pred = DT.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8045333333333333\n"
     ]
    }
   ],
   "source": [
    "DT=KNeighborsClassifier(n_neighbors=9)\n",
    "cnt_vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=1000)\n",
    "features = cnt_vectorizer.fit_transform(df['review'])\n",
    "features_nd = features.toarray()\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_nd, df['sentiment'], train_size=0.75, random_state=1234)\n",
    "DT.fit(features_nd, df['sentiment'])\n",
    "y_pred = DT.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting Lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.878\n"
     ]
    }
   ],
   "source": [
    "DT=GradientBoostingClassifier(max_depth=5,min_samples_leaf=32,min_samples_split=3,n_estimators=200)\n",
    "cnt_vectorizer = CountVectorizer(ngram_range=(1, 2), max_features=500)\n",
    "features = cnt_vectorizer.fit_transform(df['review'])\n",
    "features_nd = features.toarray()\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_nd, df['sentiment'], train_size=0.75, random_state=1234)\n",
    "DT.fit(features_nd, df['sentiment'])\n",
    "y_pred = DT.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNB_TEST_BASIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY TEST: 0.8585\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "df=pd.read_csv(\"train.csv\")\n",
    "df_test=pd.read_csv(\"test.csv\")\n",
    "TfidfVectorizer=TfidfVectorizer(ngram_range=(1, 2), max_features=5000)\n",
    "features = TfidfVectorizer.fit_transform(df['review'])\n",
    "features_nd = features.toarray()\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_nd, df['sentiment'], train_size=0.75, random_state=1234)\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "features_test = TfidfVectorizer.transform(df_test['review'])\n",
    "features_test_nd = features_test.toarray()\n",
    "y_pred = clf.predict(features_test_nd)\n",
    "print(\"ACCURACY TEST:\",accuracy_score(df_test['sentiment'], y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF_TEST_BASIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY TEST: 0.821\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "df=pd.read_csv(\"train.csv\")\n",
    "df_test=pd.read_csv(\"test.csv\")\n",
    "CountVectorizer=CountVectorizer(ngram_range=(1, 3), max_features=5000)\n",
    "features = CountVectorizer.fit_transform(df['review'])\n",
    "features_nd = features.toarray()\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_nd, df['sentiment'], train_size=0.75, random_state=1234)\n",
    "clf = RandomForestClassifier(max_depth=7,min_samples_leaf=16,min_samples_split=5,n_estimators=200)\n",
    "clf.fit(X_train, y_train)\n",
    "features_test = CountVectorizer.transform(df_test['review'])\n",
    "features_test_nd = features_test.toarray()\n",
    "y_pred = clf.predict(features_test_nd)\n",
    "print(\"ACCURACY TEST:\",accuracy_score(df_test['sentiment'], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN_TEST_BASIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY TESt: 0.63\n"
     ]
    }
   ],
   "source": [
    "KNN=KNeighborsClassifier(n_neighbors=9)\n",
    "KNN.fit(X_train, y_train)\n",
    "y_pred = KNN.predict(features_test_nd)\n",
    "print(\"ACCURACY TESt:\",accuracy_score(df_test['sentiment'], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STOP WORD AND STEMMED TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "df_stemmed=pd.read_csv(\"train.csv\")\n",
    "df_test_stemmed=pd.read_csv(\"test.csv\")\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.add('.')\n",
    "stop_words.add('<')\n",
    "stop_words.add('>')\n",
    "stop_words.add('?')\n",
    "stop_words.add('br')\n",
    "stop_words.add('/')\n",
    "stop_words.add('.')\n",
    "for i in range(len(df_stemmed['review'])):\n",
    "    word_tokens = word_tokenize(df_stemmed['review'][i])\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words and w != ',']\n",
    "    filtered_sentence = []\n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words and w != ',':\n",
    "            filtered_sentence.append(w)\n",
    "    df_stemmed['review'][i] = ' '.join(filtered_sentence)\n",
    "    df_stemmed['review'][i] = df_stemmed['review'][i].lower()\n",
    "stem=PorterStemmer()\n",
    "for i in range(len(df_stemmed['review'])):\n",
    "    words = word_tokenize(df_stemmed['review'][i])\n",
    "    words = [stem.stem(word) for word in words]\n",
    "    df_stemmed['review'][i] = ' '.join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_test_stemmed['review'])):\n",
    "    word_tokens_test = word_tokenize(df_test_stemmed['review'][i])\n",
    "    filtered_sentence_test = [w for w in word_tokens_test if not w in stop_words and w != ',']\n",
    "    filtered_sentence_test = []\n",
    "    for w in word_tokens_test:\n",
    "        if w not in stop_words and w != ',':\n",
    "            filtered_sentence_test.append(w)\n",
    "    df_test_stemmed['review'][i] = ' '.join(filtered_sentence_test)\n",
    "    df_test_stemmed['review'][i] = df_test_stemmed['review'][i].lower()\n",
    "stem=PorterStemmer()\n",
    "for i in range(len(df_test_stemmed['review'])):\n",
    "    words = word_tokenize(df_test_stemmed['review'][i])\n",
    "    words = [stem.stem(word) for word in words]\n",
    "    df_test_stemmed['review'][i] = ' '.join(words)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY TEST: 0.85395\n"
     ]
    }
   ],
   "source": [
    "TfidfVectorizer=TfidfVectorizer(ngram_range=(1, 2), max_features=5000)\n",
    "features = TfidfVectorizer.fit_transform(df_stemmed['review'])\n",
    "features_nd = features.toarray()\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_nd, df_stemmed['sentiment'], train_size=0.75, random_state=1234)\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "features_test = TfidfVectorizer.transform(df_test_stemmed['review'])\n",
    "features_test_nd = features_test.toarray()\n",
    "y_pred = clf.predict(features_test_nd)\n",
    "print(\"ACCURACY TEST:\",accuracy_score(df_test_stemmed['sentiment'], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF_STEMMED_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY TEST: 0.8235\n"
     ]
    }
   ],
   "source": [
    "TfidfVectorize=CountVectorizer(ngram_range=(1, 3), max_features=5000)\n",
    "features = TfidfVectorize.fit_transform(df_stemmed['review'])\n",
    "features_nd = features.toarray()\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_nd, df_stemmed['sentiment'], train_size=0.75, random_state=1234)\n",
    "clf = RandomForestClassifier(max_depth=7,min_samples_leaf=16,min_samples_split=5,n_estimators=200)\n",
    "clf.fit(X_train, y_train)\n",
    "features_test = TfidfVectorize.transform(df_test_stemmed['review'])\n",
    "features_test_nd = features_test.toarray()\n",
    "y_pred = clf.predict(features_test_nd)\n",
    "print(\"ACCURACY TEST:\",accuracy_score( df_test_stemmed['sentiment'], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GB_STEMMED_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY TEST: 0.82305\n"
     ]
    }
   ],
   "source": [
    "TfidfVectorize= CountVectorizer(ngram_range=(1,2),max_features=500)\n",
    "features = TfidfVectorize.fit_transform(df_stemmed['review'])\n",
    "features_nd = features.toarray()\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_nd, df_stemmed['sentiment'], train_size=0.75, random_state=1234)\n",
    "clf = GradientBoostingClassifier(max_depth=5,min_samples_leaf=32,min_samples_split=3,n_estimators=200)\n",
    "clf.fit(X_train, y_train)\n",
    "features_test = TfidfVectorize.transform(df_test_stemmed['review'])\n",
    "features_test_nd = features_test.toarray()\n",
    "y_pred = clf.predict(features_test_nd)\n",
    "print(\"ACCURACY TEST:\",accuracy_score( df_test_stemmed['sentiment'], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN_STEMMED_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY TEST: 0.7255\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "TfidfVectorize=TfidfVectorizer(ngram_range=(1, 2), max_features=1000)\n",
    "features = TfidfVectorize.fit_transform(df_stemmed['review'])\n",
    "features_nd = features.toarray()\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_nd, df_stemmed['sentiment'], train_size=0.75, random_state=1234)\n",
    "clf = KNeighborsClassifier(n_neighbors=9)\n",
    "clf.fit(X_train, y_train)\n",
    "features_test = TfidfVectorize.transform(df_test_stemmed['review'])\n",
    "features_test_nd = features_test.toarray()\n",
    "y_pred = clf.predict(features_test_nd)\n",
    "print(\"ACCURACY TEST:\",accuracy_score( df_test_stemmed['sentiment'], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STOP WORD AND LEMMATIZED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "WordNetLemmatizer\n",
    "df_lemmatized=pd.read_csv(\"train.csv\")\n",
    "df_test_lemmatized=pd.read_csv(\"test.csv\")\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.add('.')\n",
    "stop_words.add('<')\n",
    "stop_words.add('>')\n",
    "stop_words.add('?')\n",
    "stop_words.add('br')\n",
    "stop_words.add('/')\n",
    "stop_words.add('.')\n",
    "for i in range(len(df_lemmatized['review'])):\n",
    "    word_tokens = word_tokenize(df_lemmatized['review'][i])\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words and w != ',']\n",
    "    filtered_sentence = []\n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words and w != ',':\n",
    "            filtered_sentence.append(w)\n",
    "    df_lemmatized['review'][i] = ' '.join(filtered_sentence)\n",
    "    df_lemmatized['review'][i] = df_lemmatized['review'][i].lower()\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "for i in range(len(df_lemmatized['review'])):\n",
    "    words = word_tokenize(df_lemmatized['review'][i])\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    df_lemmatized['review'][i] = ' '.join(words)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_test_stemmed['review'])):\n",
    "    word_tokens_test = word_tokenize(df_test_stemmed['review'][i])\n",
    "    filtered_sentence_test = [w for w in word_tokens_test if not w in stop_words and w != ',']\n",
    "    filtered_sentence_test = []\n",
    "    for w in word_tokens_test:\n",
    "        if w not in stop_words and w != ',':\n",
    "            filtered_sentence_test.append(w)\n",
    "    df_test_stemmed['review'][i] = ' '.join(filtered_sentence_test)\n",
    "    df_test_stemmed['review'][i] = df_test_stemmed['review'][i].lower()\n",
    "lemmatize=WordNetLemmatizer()\n",
    "for i in range(len(df_test_stemmed['review'])):\n",
    "    words = word_tokenize(df_test_stemmed['review'][i])\n",
    "    words = [lemmatize.lemmatize(word) for word in words]\n",
    "    df_test_stemmed['review'][i] = ' '.join(words)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY TEST: 0.81425\n"
     ]
    }
   ],
   "source": [
    "TfidfVectorizer=TfidfVectorizer(ngram_range=(1, 2), max_features=5000)\n",
    "features = TfidfVectorizer.fit_transform(df_lemmatized['review'])\n",
    "features_nd = features.toarray()\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_nd, df_lemmatized['sentiment'], train_size=0.75, random_state=1234)\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train, y_train)\n",
    "features_test = TfidfVectorizer.transform(df_test_lemmatized['review'])\n",
    "features_test_nd = features_test.toarray()\n",
    "y_pred = clf.predict(features_test_nd)\n",
    "print(\"ACCURACY TEST:\",accuracy_score(df_test_lemmatized['sentiment'], y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RF_LEMMATIZED_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY TEST: 0.818\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "fidfVectorizer=CountVectorizer(ngram_range=(1, 3), max_features=5000)\n",
    "features = fidfVectorizer.fit_transform(df_lemmatized['review'])\n",
    "features_nd = features.toarray()\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_nd, df_lemmatized['sentiment'], train_size=0.75, random_state=1234)\n",
    "clf = RandomForestClassifier(max_depth=7,min_samples_leaf=16,min_samples_split=5,n_estimators=200)\n",
    "clf.fit(X_train, y_train)\n",
    "features_test = fidfVectorizer.transform(df_test_lemmatized['review'])\n",
    "features_test_nd = features_test.toarray()\n",
    "y_pred = clf.predict(features_test_nd)\n",
    "print(\"ACCURACY TEST:\",accuracy_score(df_test_lemmatized['sentiment'], y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN_LEMMATIZED_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY TEST: 0.57915\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "Vectorize=TfidfVectorizer(ngram_range=(1, 2), max_features=1000)\n",
    "features = Vectorize.fit_transform(df_lemmatized['review'])\n",
    "features_nd = features.toarray()\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_nd, df_lemmatized['sentiment'], train_size=0.75, random_state=1234)\n",
    "clf = KNeighborsClassifier(n_neighbors=9)\n",
    "clf.fit(X_train, y_train)\n",
    "features_test = Vectorize.transform(df_test_lemmatized['review'])\n",
    "features_test_nd = features_test.toarray()\n",
    "y_pred = clf.predict(features_test_nd)\n",
    "print(\"ACCURACY TEST:\",accuracy_score(df_test_lemmatized['sentiment'], y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GB_LEMMATIZED_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY TEST: 0.8149\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "fidfVectorizer=CountVectorizer(ngram_range=(1, 2), max_features=500)\n",
    "features = fidfVectorizer.fit_transform(df_lemmatized['review'])\n",
    "features_nd = features.toarray()\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_nd, df_lemmatized['sentiment'], train_size=0.75, random_state=1234)\n",
    "clf = GradientBoostingClassifier(max_depth=5,min_samples_leaf=32,min_samples_split=3,n_estimators=200)\n",
    "clf.fit(X_train, y_train)\n",
    "features_test = fidfVectorizer.transform(df_test_lemmatized['review'])\n",
    "features_test_nd = features_test.toarray()\n",
    "y_pred = clf.predict(features_test_nd)\n",
    "print(\"ACCURACY TEST:\",accuracy_score(df_test_lemmatized['sentiment'], y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
